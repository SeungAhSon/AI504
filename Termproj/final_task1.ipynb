{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Python Libraries\n",
    "#------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read user_itemset_training.csv and Analyze\n",
    "#------------------------------\n",
    "\n",
    "data_u_is_train = pd.read_csv('./dataset/user_itemset_training.csv', sep=',', header=None)\n",
    "data_u_is_train[0] = 'U'+data_u_is_train[0].astype(str)\n",
    "data_u_is_train[1] = 'IS'+data_u_is_train[1].astype(str)\n",
    "print(data_u_is_train.shape)\n",
    "data_u_is_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking jaccard_similarity -1\n",
    "def jaccard_similarity(G, u, v):\n",
    "    unbrs = set(G[u])\n",
    "    vnbrs = set(G[v])\n",
    "    return float(len(unbrs & vnbrs)) / len(unbrs | vnbrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking jaccard_similarity -1\n",
    "def jaccard_similarity1(s1, s2):\n",
    "    s1 = set(s1)\n",
    "    s2 = set(s2)\n",
    "    return float(len(s1.intersection(s2))/len(s1.union(s2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user projected graph\n",
    "data_u_is_train_set = {(x[0], x[1]) for x in zip(data_u_is_train[0], data_u_is_train[1])}\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "X = data_u_is_train[0].unique()\n",
    "Y = data_u_is_train[1].unique()\n",
    "\n",
    "\n",
    "B = nx.Graph()\n",
    "B.add_nodes_from(X, bipartite=0)\n",
    "B.add_nodes_from(Y, bipartite=1)\n",
    "B.add_edges_from(data_u_is_train_set)\n",
    "\n",
    "G1 = bipartite.projected_graph(B, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = list(G1.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proj = pd.DataFrame(temp, columns=['U1', 'U2'])\n",
    "\n",
    "print('Train Dataframe')\n",
    "train_proj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_data = train_proj[['U2', 'U1']].rename(columns={'U2': 'U1', 'U1': 'U2'})\n",
    "train_proj_total = pd.concat([train_proj, reversed_data], ignore_index=True)\n",
    "train_proj_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proj_total['NewCol'] = 1 / train_proj_total.groupby('U1')['U1'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proj_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_u_is_valid_query = pd.read_csv('./dataset/user_itemset_valid_query.csv', sep=',', header=None)\n",
    "data_u_is_valid_answer = pd.read_csv('./dataset/user_itemset_valid_answer.csv', sep=',', header=None)\n",
    "\n",
    "data_u_is_valid_query[0] = 'U'+data_u_is_valid_query[0].astype(str)\n",
    "data_u_is_valid_query[1] = 'IS'+data_u_is_valid_query[1].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_u_is_valid_answer = data_u_is_valid_answer.rename({0: 'X'}, axis=1)\n",
    "df_concat = pd.concat([data_u_is_valid_query, data_u_is_valid_answer], axis=1)\n",
    "\n",
    "data_u_is_valid_df = df_concat.copy()\n",
    "print('Valid Dataframe')\n",
    "data_u_is_valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "import operator\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "x_list = data_u_is_valid_df[0].tolist()\n",
    "y_list = data_u_is_valid_df[1].tolist()\n",
    "z_list = data_u_is_valid_df['X'].tolist()\n",
    "save_ans = []\n",
    "\n",
    "len_x_list = len(x_list)\n",
    "\n",
    "print('trial', '%-7s'%'i', '%-7s'%'len', '%-7s'%'real', '%-7s'%'pred')\n",
    "\n",
    "with open('user_itemset_valid_prediction.csv', 'a', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    \n",
    "    for i in range(len_x_list):\n",
    "        print(\"----\")\n",
    "        print('i',i)\n",
    "        x = x_list[i]\n",
    "        y = y_list[i]\n",
    "        z = z_list[i]\n",
    "        ans1 = 0\n",
    "        deno1 = 0\n",
    "\n",
    "        rank1_list = list(set(train_proj_total[train_proj_total['U1'] == x]['U2']))\n",
    "        for j in rank1_list:\n",
    "            temp = list(train_proj_total[(train_proj_total['U1']==x)&(train_proj_total['U2']==j)]['NewCol'])[0]\n",
    "            deno1+=temp\n",
    "            ans1+=temp* (0 if data_u_is_train[(data_u_is_train[0] == j) & (data_u_is_train[1] == y)].empty else 1)\n",
    "   \n",
    "        writer.writerows([[ans1]])\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_u_is_test_query = pd.read_csv('./dataset/user_itemset_test_query.csv', sep=',', header=None)\n",
    "\n",
    "data_u_is_test_query[0] = 'U'+data_u_is_test_query[0].astype(str)\n",
    "data_u_is_test_query[1] = 'IS'+data_u_is_test_query[1].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "x_list = data_u_is_test_query[0].tolist()\n",
    "y_list = data_u_is_test_query[1].tolist()\n",
    "save_ans = []\n",
    "\n",
    "len_x_list = len(x_list)\n",
    "\n",
    "print('trial', '%-7s'%'i', '%-7s'%'len', '%-7s'%'real', '%-7s'%'pred')\n",
    "\n",
    "with open('user_itemset_test_prediction.csv', 'a', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    \n",
    "    for i in range(len_x_list):\n",
    "        print(\"----\")\n",
    "        print('i',i)\n",
    "        x = x_list[i]\n",
    "        y = y_list[i]\n",
    "        ans1 = 0\n",
    "        deno1 = 0\n",
    "\n",
    "        rank1_list = list(set(train_proj_total[train_proj_total['U1'] == x]['U2']))\n",
    "        for j in rank1_list:\n",
    "            temp = list(train_proj_total[(train_proj_total['U1']==x)&(train_proj_total['U2']==j)]['NewCol'])[0]\n",
    "            deno1+=temp\n",
    "            ans1+=temp* (0 if data_u_is_train[(data_u_is_train[0] == j) & (data_u_is_train[1] == y)].empty else 1)\n",
    "        \n",
    "        if ans1>0.0005 : ans1 = 1\n",
    "        else : ans1 = 0\n",
    "        writer.writerows([[ans1]])\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
